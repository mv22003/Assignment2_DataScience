{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef5a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cross-Validation\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# Prediction Scoring\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import make_scorer\n",
    "from statistics import mean\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d95fb",
   "metadata": {},
   "source": [
    "### Loading the test group for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bfa35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features from control  \n",
    "df = pd.read_csv('Final_Features_control.csv')\n",
    "\n",
    "# Scale data for better perfomance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Extract name of columns in df as a list\n",
    "columns = list(df.columns)\n",
    "\n",
    "# Eliminate both participant name and empathy column because they are not a features\n",
    "columns.pop(0)  \n",
    "columns.pop(-1)\n",
    "\n",
    "# Scale data by columns \n",
    "df[columns] = scaler.fit_transform(df[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fcb799",
   "metadata": {},
   "source": [
    "### Categorizing our label\n",
    "We are passing our label from a continuous to a discrete variable for a better __interpretation__ of the results and for the __simplicity__ of the predictions. We use the `pd.cut` function from pandas to create the bins and the respective label. In __Table 1__, we explain the process done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08d9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretizing my label/target\n",
    "df['Empathy Score'] = pd.cut(df[\"Empathy Score\"],\n",
    "       bins=[80, 100, 110, 120, 130], \n",
    "       labels=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa3cdb6",
   "metadata": {},
   "source": [
    "### <center> Table 1\n",
    "| Empathy Range | Class | Label |\n",
    "| :-: | :-: | :-: |\n",
    "| <100 | Bad | 0 |\n",
    "| 100-110 | Average | 1 |\n",
    "| 110-120 | Good | 2 |\n",
    "| >120 | Outstanding | 3 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b0372a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant name</th>\n",
       "      <th>Mean Pupil diameter left</th>\n",
       "      <th>Std Pupil diameter left</th>\n",
       "      <th>Mean Pupil diameter right</th>\n",
       "      <th>Std Pupil diameter right</th>\n",
       "      <th>Num. of Fixations</th>\n",
       "      <th>Num. of Saccades</th>\n",
       "      <th>Num. of Unclassified</th>\n",
       "      <th>Recording duration (s)</th>\n",
       "      <th>Mean Gaze event duration (s)</th>\n",
       "      <th>Mean Fixation point X</th>\n",
       "      <th>Std Fixation point X</th>\n",
       "      <th>Mean Fixation point Y</th>\n",
       "      <th>Std Fixation point Y</th>\n",
       "      <th>Mean Gaze point X</th>\n",
       "      <th>Std Gaze point X</th>\n",
       "      <th>Mean Gaze point Y</th>\n",
       "      <th>Std Gaze point Y</th>\n",
       "      <th>Empathy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.432974</td>\n",
       "      <td>0.419118</td>\n",
       "      <td>-0.421194</td>\n",
       "      <td>0.464759</td>\n",
       "      <td>1.587351</td>\n",
       "      <td>1.189040</td>\n",
       "      <td>-0.146779</td>\n",
       "      <td>1.194853</td>\n",
       "      <td>-0.207512</td>\n",
       "      <td>-0.634649</td>\n",
       "      <td>-0.134460</td>\n",
       "      <td>-0.991371</td>\n",
       "      <td>0.109380</td>\n",
       "      <td>-0.779279</td>\n",
       "      <td>-0.242149</td>\n",
       "      <td>-0.647180</td>\n",
       "      <td>-0.143647</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.879696</td>\n",
       "      <td>-0.040243</td>\n",
       "      <td>-0.905519</td>\n",
       "      <td>0.324219</td>\n",
       "      <td>-1.407530</td>\n",
       "      <td>-0.923646</td>\n",
       "      <td>-1.105699</td>\n",
       "      <td>-1.694376</td>\n",
       "      <td>-0.244112</td>\n",
       "      <td>0.577072</td>\n",
       "      <td>-1.720481</td>\n",
       "      <td>-0.303356</td>\n",
       "      <td>0.415151</td>\n",
       "      <td>0.549348</td>\n",
       "      <td>-1.829771</td>\n",
       "      <td>0.165859</td>\n",
       "      <td>0.930937</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.617033</td>\n",
       "      <td>-0.581028</td>\n",
       "      <td>-0.705775</td>\n",
       "      <td>-0.525981</td>\n",
       "      <td>-1.541145</td>\n",
       "      <td>-0.881219</td>\n",
       "      <td>-0.809038</td>\n",
       "      <td>-1.657819</td>\n",
       "      <td>-0.247426</td>\n",
       "      <td>0.403903</td>\n",
       "      <td>-1.320230</td>\n",
       "      <td>-0.103427</td>\n",
       "      <td>-1.240654</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>-1.203205</td>\n",
       "      <td>-0.003172</td>\n",
       "      <td>-1.156548</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.633217</td>\n",
       "      <td>-0.447870</td>\n",
       "      <td>-0.617493</td>\n",
       "      <td>-0.373333</td>\n",
       "      <td>-1.564468</td>\n",
       "      <td>-1.079856</td>\n",
       "      <td>-1.144688</td>\n",
       "      <td>-1.825463</td>\n",
       "      <td>-0.126731</td>\n",
       "      <td>-0.448392</td>\n",
       "      <td>-0.947675</td>\n",
       "      <td>-0.038253</td>\n",
       "      <td>-0.046150</td>\n",
       "      <td>-0.476786</td>\n",
       "      <td>-1.194187</td>\n",
       "      <td>0.082513</td>\n",
       "      <td>-0.257640</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.556424</td>\n",
       "      <td>-0.003391</td>\n",
       "      <td>-0.456996</td>\n",
       "      <td>0.333323</td>\n",
       "      <td>3.975823</td>\n",
       "      <td>4.980497</td>\n",
       "      <td>2.402240</td>\n",
       "      <td>5.025200</td>\n",
       "      <td>-0.283657</td>\n",
       "      <td>-0.484989</td>\n",
       "      <td>0.319513</td>\n",
       "      <td>-0.290735</td>\n",
       "      <td>0.524766</td>\n",
       "      <td>-0.619729</td>\n",
       "      <td>0.268810</td>\n",
       "      <td>0.013531</td>\n",
       "      <td>0.388368</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant name  Mean Pupil diameter left  Std Pupil diameter left  \\\n",
       "0               2.0                 -0.432974                 0.419118   \n",
       "1               2.0                 -0.879696                -0.040243   \n",
       "2               2.0                 -0.617033                -0.581028   \n",
       "3               2.0                 -0.633217                -0.447870   \n",
       "4               2.0                 -0.556424                -0.003391   \n",
       "\n",
       "   Mean Pupil diameter right  Std Pupil diameter right  Num. of Fixations  \\\n",
       "0                  -0.421194                  0.464759           1.587351   \n",
       "1                  -0.905519                  0.324219          -1.407530   \n",
       "2                  -0.705775                 -0.525981          -1.541145   \n",
       "3                  -0.617493                 -0.373333          -1.564468   \n",
       "4                  -0.456996                  0.333323           3.975823   \n",
       "\n",
       "   Num. of Saccades  Num. of Unclassified  Recording duration (s)  \\\n",
       "0          1.189040             -0.146779                1.194853   \n",
       "1         -0.923646             -1.105699               -1.694376   \n",
       "2         -0.881219             -0.809038               -1.657819   \n",
       "3         -1.079856             -1.144688               -1.825463   \n",
       "4          4.980497              2.402240                5.025200   \n",
       "\n",
       "   Mean Gaze event duration (s)  Mean Fixation point X  Std Fixation point X  \\\n",
       "0                     -0.207512              -0.634649             -0.134460   \n",
       "1                     -0.244112               0.577072             -1.720481   \n",
       "2                     -0.247426               0.403903             -1.320230   \n",
       "3                     -0.126731              -0.448392             -0.947675   \n",
       "4                     -0.283657              -0.484989              0.319513   \n",
       "\n",
       "   Mean Fixation point Y  Std Fixation point Y  Mean Gaze point X  \\\n",
       "0              -0.991371              0.109380          -0.779279   \n",
       "1              -0.303356              0.415151           0.549348   \n",
       "2              -0.103427             -1.240654           0.527018   \n",
       "3              -0.038253             -0.046150          -0.476786   \n",
       "4              -0.290735              0.524766          -0.619729   \n",
       "\n",
       "   Std Gaze point X  Mean Gaze point Y  Std Gaze point Y Empathy Score  \n",
       "0         -0.242149          -0.647180         -0.143647             2  \n",
       "1         -1.829771           0.165859          0.930937             2  \n",
       "2         -1.203205          -0.003172         -1.156548             2  \n",
       "3         -1.194187           0.082513         -0.257640             2  \n",
       "4          0.268810           0.013531          0.388368             2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print DataFrame to see the results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5989ca",
   "metadata": {},
   "source": [
    "### Split data using KFolds\n",
    "We are splitting our training and testing data using Group KFolds because of the nature of our labels, in essence we have a bunch of rows that that share the same label so we dont want any leakage of data from the testing data to the training data. In this code we separate the features and our label first and then create the k-folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb7ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop participant name and empathy column because they are not a feature\n",
    "X = df.drop(['Participant name','Empathy Score'], axis=1)\n",
    "\n",
    "# Store label in variable 'y'\n",
    "y = df['Empathy Score']\n",
    "\n",
    "# Store group indexes in 'gps'\n",
    "gps = df['Participant name']\n",
    "\n",
    "# Create Group KFolds\n",
    "kf = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffced05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X, y, groups=gps):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0d98a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 17)\n",
      "(31, 17)\n",
      "(116,)\n",
      "(31,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c65e03",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59c519a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SGDC:     0.37 +/- 0.05 \n",
      "\n",
      "Accuracy NCC:      0.28 +/- 0.07\n",
      "Accuracy NN:       0.35 +/- 0.09\n",
      "Accuracy LOGR:     0.39 +/- 0.10 *** \n",
      "\n",
      "Accuracy Adaboost: 0.28 +/- 0.08\n",
      "Accuracy DT:       0.30 +/- 0.08\n",
      "Accuracy RFR:      0.33 +/- 0.09 \n",
      "\n",
      "Accuracy KNN:      0.38 +/- 0.11\n",
      "Accuracy SVC:      0.32 +/- 0.06\n",
      "Accuracy Dummy:    0.40 +/- 0.08\n"
     ]
    }
   ],
   "source": [
    "# DUMMY CLASSIFIER\n",
    "dummy = DummyClassifier(strategy ='prior') \n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = cross_val_score(dummy, X, y, cv=kf, groups=gps, scoring='balanced_accuracy')\n",
    "\n",
    "# DECISION TREE CLASSIFIER\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = cross_val_score(dt, X, y, cv=kf, groups=gps, scoring='balanced_accuracy')\n",
    "\n",
    "# ADABOOST CLASSIFIER\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred_ada = cross_val_score(ada, X, y, cv=kf, groups=gps, scoring='balanced_accuracy')\n",
    "\n",
    "# NN CLASSIFIER\n",
    "nn = MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(5, 2),random_state=1)\n",
    "nn.fit(X_train, y_train)\n",
    "y_pred_nn = cross_val_score(nn, X, y, cv=kf, groups=gps, scoring='balanced_accuracy')\n",
    "\n",
    "# SVM CLASSIFIER\n",
    "svc = SVC(random_state=13)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = cross_val_score(svc, X, y, cv=kf, groups=gps, scoring='balanced_accuracy')\n",
    "\n",
    "# SGD CLASSIFIER\n",
    "sgd = SGDClassifier(random_state=13)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred_sgd = cross_val_score(sgd, X, y, cv=kf, groups=gps, scoring='balanced_accuracy')\n",
    "\n",
    "# KNN CLASSIFIER\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = cross_val_score(knn, X, y, cv=kf, groups=gps, scoring='balanced_accuracy')\n",
    "\n",
    "# NEAREST CENTROID\n",
    "ncc = NearestCentroid()\n",
    "ncc.fit(X_train, y_train)\n",
    "y_pred_ncc = cross_val_score(ncc, X, y, cv=kf, groups=gps, scoring='balanced_accuracy')\n",
    "\n",
    "# RANDOM FORREST\n",
    "rfr = RandomForestClassifier(n_estimators=300, random_state=13)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_pred_rfr = cross_val_score(rfr, X, y, cv=kf, groups=gps, scoring='balanced_accuracy')\n",
    "\n",
    "# LOGISTIC REGRESSION\n",
    "logreg = LogisticRegression(random_state=13)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = cross_val_score(logreg, X, y, cv=kf, groups=gps, scoring='balanced_accuracy')\n",
    "\n",
    "# RESULTS\n",
    "print('Accuracy SGDC:     %.2f +/- %.2f' % ((y_pred_sgd.mean()),y_pred_sgd.std()),'\\n')\n",
    "print('Accuracy NCC:      %.2f +/- %.2f' % ((y_pred_ncc.mean()),y_pred_ncc.std()))\n",
    "print('Accuracy NN:       %.2f +/- %.2f' % ((y_pred_nn.mean()),y_pred_nn.std()))\n",
    "print('Accuracy LOGR:     %.2f +/- %.2f' % ((y_pred_logreg.mean()),y_pred_logreg.std()),'***','\\n')\n",
    "print('Accuracy Adaboost: %.2f +/- %.2f' % ((y_pred_ada.mean()),y_pred_ada.std()))\n",
    "print('Accuracy DT:       %.2f +/- %.2f' % ((y_pred_dt.mean()),y_pred_dt.std()))\n",
    "print('Accuracy RFR:      %.2f +/- %.2f' % ((y_pred_rfr.mean()),y_pred_rfr.std()),'\\n')\n",
    "print('Accuracy KNN:      %.2f +/- %.2f' % ((y_pred_knn.mean()),y_pred_knn.std()))\n",
    "print('Accuracy SVC:      %.2f +/- %.2f' % ((y_pred_svc.mean()),y_pred_svc.std()))\n",
    "print('Accuracy Dummy:    %.2f +/- %.2f' % ((y_pred_dummy.mean()),y_pred_dummy.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7390c9f",
   "metadata": {},
   "source": [
    "## Explainability of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ae789",
   "metadata": {},
   "source": [
    "In the case of the __test group__, the __best classifier__ was `LogisticRegression`, so we are going to extract the best __features__ to understand the __behaviour__ of our predictor per class. With this in mind, we are plotting the __best predictor__ (__feature__ in this case) for each class, and their respective __coefficient or weight__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57648b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Std Gaze point X\n",
      "Coef: 0.81\n",
      "Feature: Mean Fixation point X\n",
      "Coef: 0.71\n",
      "Feature: Num. of Saccades\n",
      "Coef: 0.94\n"
     ]
    }
   ],
   "source": [
    "max_class = logreg.coef_.argmax(axis=1)\n",
    "\n",
    "for i in range(logreg.coef_.shape[0]):\n",
    "    print('Feature:', logreg.feature_names_in_[max_class[i]])\n",
    "    print('Coef: %.2f' % logreg.coef_[i,max_class[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664aecf7",
   "metadata": {},
   "source": [
    "^^^ __The outcome of this coefficient corresponds to how true is the feature to the class prediction.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d6e124",
   "metadata": {},
   "source": [
    "***CONTROL GROUP ONLY HAS EMPATHY SCORES FOR THE FIRST THREE LABELS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34d44bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 0]\n",
       "Categories (4, int64): [0 < 1 < 2 < 3]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Empathy Score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "421906a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d296b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd.coef_[3,:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53c999c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd.feature_names_in_[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16e1f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_class = sgd.coef_.argmax(axis=1)\n",
    "# max_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0275e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
